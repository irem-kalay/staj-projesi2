#import os
#from textsum.summarize import Summarizer
#tÃ¼rkÃ§ede Ã§alÄ±ÅŸmÄ±yor, bu gÃ¼zel ama ÅŸuan
# === Ayarlar ===
#input_dir = "."  # Åu anki dizin
#summarizer = Summarizer()

# === TÃ¼m .txt dosyalarÄ±nÄ± listele ===
#txt_files = [f for f in os.listdir(input_dir) if f.endswith(".txt") and "_summary" not in f and "_final_summary" not in f]

#for txt_file in txt_files:
#   print(f"ğŸ“„ Ã–zetleniyor: {txt_file}")

    # Ã–zetleme iÅŸlemi
#   summary_path = summarizer.summarize_file(txt_file)

#   print(f"âœ… Ã–zet dosyaya yazÄ±ldÄ±: {summary_path}\n")

# 1. NLTK ile Extractive Summarization (CÃ¼mle SkorlamasÄ±)
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
from collections import defaultdict
import heapq


def nltk_summarize(text, num_sentences=3):
    # Gerekli NLTK verilerini indir (ilk Ã§alÄ±ÅŸtÄ±rmada)
    try:
        nltk.data.find('tokenizers/punkt')
    except LookupError:
        nltk.download('punkt')

    try:
        nltk.data.find('corpora/stopwords')
    except LookupError:
        nltk.download('stopwords')

    # CÃ¼mlelere ayÄ±r
    sentences = sent_tokenize(text)

    # Kelime frekansÄ± hesapla
    stop_words = set(stopwords.words('english'))
    word_frequencies = defaultdict(int)

    for sentence in sentences:
        words = word_tokenize(sentence.lower())
        for word in words:
            if word not in stop_words and word.isalpha():
                word_frequencies[word] += 1

    # CÃ¼mle skorlarÄ± hesapla
    sentence_scores = defaultdict(float)
    for i, sentence in enumerate(sentences):
        words = word_tokenize(sentence.lower())
        for word in words:
            if word in word_frequencies:
                sentence_scores[i] += word_frequencies[word]

    # En yÃ¼ksek skorlu cÃ¼mleleri seÃ§
    best_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)
    best_sentences.sort()

    return ' '.join([sentences[i] for i in best_sentences])


# 2. TextRank AlgoritmasÄ± ile Ã–zetleme
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np


def textrank_summarize(text, num_sentences=3):
    sentences = sent_tokenize(text)

    if len(sentences) <= num_sentences:
        return text

    # TF-IDF vektÃ¶rleri oluÅŸtur
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(sentences)

    # Benzerlik matrisi hesapla
    similarity_matrix = cosine_similarity(tfidf_matrix)

    # PageRank algoritmasÄ± uygula
    scores = np.ones(len(sentences))
    for _ in range(100):  # 100 iterasyon
        new_scores = np.ones(len(sentences))
        for i in range(len(sentences)):
            for j in range(len(sentences)):
                if i != j:
                    new_scores[i] += similarity_matrix[i][j] * scores[j]
        scores = new_scores

    # En yÃ¼ksek skorlu cÃ¼mleleri seÃ§
    ranked_sentences = sorted(((scores[i], i) for i in range(len(sentences))), reverse=True)
    selected_indices = sorted([ranked_sentences[i][1] for i in range(num_sentences)])

    return ' '.join([sentences[i] for i in selected_indices])


# 3. Transformers ile Modern AI Ã–zetleme
from transformers import pipeline


def ai_summarize(text, max_length=150, min_length=50):
    # Hugging Face'den Ã¶zetleme modeli yÃ¼kle
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

    # Uzun metinleri parÃ§alara bÃ¶l (BART max 1024 token)
    max_chunk = 1000
    chunks = [text[i:i + max_chunk] for i in range(0, len(text), max_chunk)]

    summaries = []
    for chunk in chunks:
        if len(chunk.strip()) > 100:  # Ã‡ok kÄ±sa parÃ§alarÄ± atla
            summary = summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)
            summaries.append(summary[0]['summary_text'])

    return ' '.join(summaries)


# 4. Basit Kelime FrekansÄ± ile Ã–zetleme (Ä°yileÅŸtirilmiÅŸ)
def simple_frequency_summarize(text, num_sentences=3, min_sentence_length=10):
    sentences = sent_tokenize(text)

    # Ã‡ok kÄ±sa cÃ¼mleleri filtrele
    sentences = [s for s in sentences if len(s.split()) > min_sentence_length]

    if len(sentences) <= num_sentences:
        return ' '.join(sentences)

    # Stop words listesi
    stop_words = set(['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
                      'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have',
                      'has', 'had', 'will', 'would', 'could', 'should', 'may', 'might',
                      'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it',
                      'we', 'they', 'me', 'him', 'her', 'us', 'them', 'uh', 'um', 'so',
                      'like', 'just', 'going', 'want', 'get', 'now', 'here', 'there'])

    # Kelime frekanslarÄ±nÄ± hesapla
    word_freq = {}
    for sentence in sentences:
        words = sentence.lower().split()
        for word in words:
            # Sadece harflerden oluÅŸan kelimeleri al ve stop words'leri Ã§Ä±kar
            clean_word = ''.join(c for c in word if c.isalpha())
            if clean_word and clean_word not in stop_words and len(clean_word) > 2:
                word_freq[clean_word] = word_freq.get(clean_word, 0) + 1

    # En sÄ±k kullanÄ±lan kelimeleri al (top %20)
    if not word_freq:
        return ' '.join(sentences[:num_sentences])

    max_freq = max(word_freq.values())
    important_words = {word: freq for word, freq in word_freq.items()
                       if freq >= max_freq * 0.3}  # En az %30 frekansta olanlar

    # CÃ¼mle skorlarÄ±nÄ± hesapla
    sentence_scores = {}
    for sentence in sentences:
        words = sentence.lower().split()
        score = 0
        word_count = 0

        for word in words:
            clean_word = ''.join(c for c in word if c.isalpha())
            if clean_word in important_words:
                score += important_words[clean_word]
                word_count += 1

        # Pozisyon bonusu (baÅŸlangÄ±Ã§ cÃ¼mleleri daha Ã¶nemli)
        position_bonus = 1.0 - (sentences.index(sentence) / len(sentences)) * 0.3

        if word_count > 0:
            sentence_scores[sentence] = (score / word_count) * position_bonus

    if not sentence_scores:
        return ' '.join(sentences[:num_sentences])

    # En yÃ¼ksek skorlu cÃ¼mleleri seÃ§
    best_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)

    # Orijinal sÄ±rayÄ± koru
    result_sentences = []
    for sentence in sentences:
        if sentence in best_sentences:
            result_sentences.append(sentence.strip())

    return ' '.join(result_sentences)


# 5. YouTube/Podcast Transkripti iÃ§in Ã–zel Ã–zetleme
def transcript_summarize(text, num_sentences=5):
    """YouTube videolarÄ± ve podcast transkriptleri iÃ§in Ã¶zel Ã¶zetleme"""

    # KonuÅŸma kalÄ±plarÄ±nÄ± temizle
    text = text.replace('um ', '').replace('uh ', '').replace('like ', '')
    text = text.replace('[Music]', '').replace('[Applause]', '')

    sentences = sent_tokenize(text)

    # Teknik terimler ve anahtar kelimeler (video konusuyla ilgili)
    tech_keywords = ['python', 'pdf', 'summarize', 'langchain', 'gpt', 'claude', 'api',
                     'model', 'transformer', 'chain', 'document', 'load', 'install',
                     'code', 'function', 'file', 'key', 'anthropic', 'openai']

    # CÃ¼mle skorlama
    sentence_scores = {}
    for sentence in sentences:
        if len(sentence.split()) < 8:  # Ã‡ok kÄ±sa cÃ¼mleleri atla
            continue

        words = sentence.lower().split()
        tech_score = sum(1 for word in words if any(keyword in word for keyword in tech_keywords))

        # Uzunluk skoru (Ã§ok kÄ±sa veya Ã§ok uzun cÃ¼mlelere ceza)
        length_score = min(len(words) / 15, 1.0) if len(words) > 5 else 0.1

        # Pozisyon skoru (baÅŸlangÄ±Ã§ ve sonun Ã¶nemli olduÄŸunu varsay)
        position = sentences.index(sentence) / len(sentences)
        position_score = 1.0 if position < 0.3 or position > 0.7 else 0.7

        sentence_scores[sentence] = tech_score * length_score * position_score

    if not sentence_scores:
        return ' '.join(sentences[:num_sentences])

    # En iyi cÃ¼mleleri seÃ§
    best_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)

    # SÄ±ralama koru
    result = []
    for sentence in sentences:
        if sentence in best_sentences:
            result.append(sentence.strip())

    return ' '.join(result)


# KULLANIM Ã–RNEKLERÄ°
if __name__ == "__main__":
    # Ã–rnek metin
    sample_text = """
    Ä°yi sandviÃ§ yapmayÄ± bilirsen ÅŸu hayatta her ÅŸeyin Ã¼stesinden gelebilirsin. Neden? Ã‡Ã¼nkÃ¼ basit malzemelerle bile iyi bir yemek ortaya Ã§Ä±karÄ±yorsun. GÃ¶zÃ¼n doyuyor, yetiyor. Oysa hayat bazen elindeki en iyi malzemelerle bile sana kÃ¶tÃ¼ bir yemekmiÅŸ gibi gÃ¶rÃ¼nebilir. Tam ÅŸurada bana aynen bÃ¶yle gÃ¶rÃ¼nÃ¼yordu. E bendeki malzeme bu. Bununla bir ÅŸeyler piÅŸirmeye Ã§alÄ±ÅŸÄ±yorum iÅŸte sanki bÃ¶yle farkÄ±nda deÄŸilmiÅŸim gibi. Artist artist bozlar. Ama aslÄ±nda kafamda arka plana girip Ã§Ä±kan o tipler var. Ne zaman boÅŸaltacaklar, meydanÄ± ne zaman bana bÄ±rakacaklar filan diye dÃ¼ÅŸÃ¼nÃ¼yorum. Mesela ÅŸu adam tam en iyi pozumu yakalamÄ±ÅŸÄ±m. Fotobomp yapÄ±p duruyor. KaÃ§ kere girdi Ã§Ä±ktÄ± bu kadraja ya. En sonunda tamam dedim ya pes ettim. VazgeÃ§tim bu fotoÄŸraftan. KÃ¶tÃ¼ bir yemek bu. Ama sonra ertesi gÃ¼n Ã§ektiklerimi gÃ¶zden geÃ§irirken o adama bir daha baktÄ±m. Biraz daha yakÄ±ndan. Bu fotoÄŸraftan 30 sene Ã¶nce ona da hayatÄ±n kÃ¶tÃ¼ bir yemek gibi gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ nereden bilecektim ki? Mesela en sevdiÄŸim dizinin bir bÃ¶lÃ¼mÃ¼nÃ¼n bir parÃ§asÄ±nda palyaÃ§o kÄ±lÄ±ÄŸÄ±na bile girmek zorunda kaldÄ±ÄŸÄ±nÄ± bilemezdim. E ondaki malzeme de buymuÅŸ. Onunla yapabileceÄŸinin en iyisini yapmayÄ± denemiÅŸ. AktÃ¶r olmak istiyormuÅŸ. YÃ¼zÃ¼nÃ¼n bile gÃ¶zÃ¼kmediÄŸi bÃ¶yle rolleri kabul etmek zorunda kalmÄ±ÅŸ. E sonra bakmÄ±ÅŸ olmuyor. Kendi kaderinin kontrolÃ¼nÃ¼ kendi ellerine almÄ±ÅŸ. Bir yemeÄŸin iÃ§indeki malzeme olmaktansa o yemeÄŸi hazÄ±rlayan ÅŸef olmalÄ±yÄ±m diye dÃ¼ÅŸÃ¼nmÃ¼ÅŸ ve bunu yapmÄ±ÅŸ. Ä°ÅŸin mutfaÄŸÄ±na da geÃ§ip kendi projelerini yazmaya, kendi giriÅŸimlerini yapmaya, yÃ¶netmeye baÅŸlamÄ±ÅŸ. Ve iÅŸte bu ÅŸekilde palyaÃ§oluktan kurtulup Iron Man filmiyile baÅŸlayan o koskoca Marvel sinematik evreninin kurucularÄ±ndan biri haline gelmiÅŸ. Evet, hala bana fotobomp yapan aynÄ± adamdan bahsediyorum. EÄŸer dikkatli bakarsanÄ±z onun Jean Favro olduÄŸunu gÃ¶rebilirsiniz. DÃ¼nyanÄ±n en bÃ¼yÃ¼k Star Wars buluÅŸmasÄ±nda kapalÄ± bir etkinlik sÄ±rasÄ±nda Ã§ekilen bu fotoÄŸrafta beni sinir eden adamÄ±n o olduÄŸunu keÅŸke daha Ã¶nce anlayabilseydim. Ã‡Ã¼nkÃ¼ oraya yine kendi projesi olan Mandalorean'Ä±n yeni sezon tanÄ±tÄ±mÄ± iÃ§in gelmiÅŸti. O artÄ±k dizilerde bir figÃ¼r olmaktan Ã§Ä±kÄ±p sinematik evrenler kurgulayan Hollywood'un en Ã¶nemli yÃ¶netmenlerinden biri olmuÅŸtu. Yoksa ÅŸef mi demeliyiz? Evet, ÅŸef daha iyi bir tabir olur. DÃ¼nyanÄ±n en bÃ¼yÃ¼k restoranlarÄ±nda en iyi malzemelerle gÃ¶rkemli yemekler hazÄ±rlayan bir ÅŸef gibi yÃ¶netmen. Ama hayat Ã¶yle bir ÅŸey ki iniÅŸ Ã§Ä±kÄ±ÅŸlarla dolu. Ã–yle sadece hamdÄ±m piÅŸtim olmuyor. Bazen yanmak da gerekiyor ki kÃ¼llerinden tekrar doÄŸabilesin. Ä°ÅŸte Jean Favro'nun hayatÄ±nda da aynen bÃ¶yle bir dÃ¶nem var. Onun grafiÄŸi PalyaÃ§o Erik karakteriyle ta en aÅŸaÄŸÄ±dan baÅŸlÄ±yor ve Iron Man filmleriyle en tepeye kadar Ã§Ä±kÄ±yor. Ãœstelik o filmlerde hem yÃ¶netmen hem de Iron Man'in ÅŸofÃ¶rÃ¼ Happy Hogan rolÃ¼nde. Evet, karakterin adÄ± Happy. Mutlu anlamÄ±na geliyor ama onu canlandÄ±ran Jean Favro hiÃ§ de mutlu deÄŸil o yÄ±llarda. Demek ki zirvede bile kaybolabilmek mÃ¼mkÃ¼n. Devasa bÃ¼tÃ§eli filmlerdeki beklentiler hiÃ§ bitmiyor. YÃ¼zlerce kiÅŸilik ekipler onu bunaltÄ±yor. Her ÅŸeyi bir kenara bÄ±rakÄ±p yeniden baÅŸlamak istiyor. Kendi hikayesini kendi kurallarÄ±yla anlatma ihtiyacÄ± bu. Onun grafiÄŸindeki bu dÃ¶nemeci Ã§ok iyi okumamÄ±z lazÄ±m. Ã‡Ã¼nkÃ¼ hepimizi ilgilendiren Ã¶nemli dersler var. Yani palyaÃ§o ya da aktÃ¶r olmayÄ± dÃ¼ÅŸÃ¼nmÃ¼yorsanÄ±z bile ÅŸimdi biraz daha kulak kabartÄ±n. Ã‡Ã¼nkÃ¼ bazen gerÃ§ekten yanmak ve en baÅŸa, en temele dÃ¶nmek gerekiyor ki kÃ¼llerinizden asÄ±l siz olarak doÄŸabilesiniz. Jean Favro 2014'te sÃ¼per kahramanlarla uÄŸraÅŸmaya bir ara verip kendi imkanlarÄ±yla mÃ¼tevazi bir film Ã§ekti. Åef bu filmi bana kÄ±saca tanÄ±t dersen eÄŸer iyi sandviÃ§ yapmakla ilgili bir film derim. Ã‡ok basit bir hikaye. Ã–yle bÃ¼yÃ¼k Ã§atÄ±ÅŸmalar yok. Aksiyon neredeyse sÄ±fÄ±r. Romantizm yani biraz var ama arka planda. Ä°ÅŸte o yÃ¼zden de yani tÃ¼m bu unsurlarÄ±n Ã§ok geri planda kalmasÄ± nedeniyle Ã§ok da bilinmiyor bu film. Ama izleyince of sizi Ã¶yle bir yakalÄ±yor ki tadÄ± damaÄŸÄ±nÄ±zda kalÄ±yor. Ä°yi bir restoranda Ã¼nlÃ¼ bir ÅŸef olarak Ã§alÄ±ÅŸan birinin hikayesi bu. Ãœstelik teknolojiyle de bir ilgisi var. O yÄ±llarda en Ã¶nemli teknoloji trendi sosyal medyaydÄ±. X'in Twitter olduÄŸu yÄ±llar hatta Twitter'Ä±n Wine'i Ã§Ä±kardÄ±ÄŸÄ± yÄ±llar yani 6 saniyede meÅŸhur olabildiÄŸiniz zamanlar. Ä°ÅŸte o zaman da ÅŸimdiki gibi teknoloji bazÄ±larÄ±na fÄ±rsat sunuyor. BazÄ±larÄ±nÄ±n da iÅŸini yok ediyordu. Klasik bÄ±Ã§ak Ã¶rneÄŸi. Birisini Ã¶ldÃ¼rebilir ve baÅŸka birini tedavi edebilir ya da bir ÅŸefin elinde nefis bir yemek hazÄ±rlayabilir. Ä°ÅŸte o yÄ±llarÄ±n yÃ¼kselen teknolojisi. Sosyal medya bizim bu geleneksel ÅŸefin iÅŸlerini bozuyor. bir gurmenin yazdÄ±ÄŸÄ± eleÅŸtiri yazÄ±sÄ±na Twitter DM'den Ã¶zel bir cevap verdiÄŸini sanÄ±p o mesajÄ± herkese aÃ§Ä±k yollayÄ±nca bir gÃ¼zel linÃ§ yiyip yerine oturuyor ve bir gÃ¼nde hem iÅŸini hem de itibarÄ±nÄ± kaybediyor. >> E bakÄ±n 10 yÄ±l sonra bugÃ¼n de baÅŸka bir teknolojik tehditle karÅŸÄ± karÅŸÄ±yayÄ±z deÄŸil mi? Yapay zeka tehdidi. MesleÄŸimiz elimizden alÄ±nacak mÄ± korkusu yaÅŸÄ±yoruz. Yapay zeka bizim yeni bÄ±Ã§aÄŸÄ±mÄ±z ama onu nasÄ±l kullanmalÄ±yÄ±z? Bizim her ÅŸeyini kaybeden o ÅŸefimiz sÄ±fÄ±rdan baÅŸlamaya karar veriyor. Eskiden mutfakta bir sÃ¼rÃ¼ kiÅŸiyi yÃ¶netip sofistike menÃ¼ler hazÄ±rlarken iÅŸinden olmuÅŸtu. AynÄ± ÅŸeyi denemek yerine baÅŸka bir restoranda aynÄ± yÃ¶ntemlerle yine karmaÅŸÄ±k iÅŸ akÄ±ÅŸlarÄ± kullanmak yerine kendisine yeni bir Ã§Ä±kÄ±ÅŸ yolu ararken en temele inmeye karar veriyor. >> Eski eÅŸinin yardÄ±mÄ±yla eski bir yemek kamyonu buluyor. eski iÅŸi sÄ±rasÄ±nda Ã§okÃ§a ihmal ettiÄŸi kÃ¼Ã§Ã¼k oÄŸluyla o kamyonu temizleyip bir gÃ¼zel adam ediyor ve eski bir arkadaÅŸÄ±yla birlikte sandviÃ§ yapmaya baÅŸlÄ±yorlar. Eski eski deyip duruyorum Ã§Ã¼nkÃ¼ bazÄ± ÅŸeyler deÄŸiÅŸmiyor. BÃ¶ylesine hÄ±zla deÄŸiÅŸen zamanlarda deÄŸiÅŸmeyen o eskileri bulup onlara tutunup onlarÄ± yenilerle buluÅŸturup bir fÃ¼zyon yapmak gerekiyor. AynÄ± ikilem belki ÅŸu anda sizin Ã¶nÃ¼nÃ¼zde de var. Belki siz de tutkuyla bir ÅŸeyler yapmaya Ã§alÄ±ÅŸÄ±yorsunuz ama hep teknoloji engeliyle karÅŸÄ±laÅŸÄ±yorsunuz. AslÄ±nda biraz araÅŸtÄ±rÄ±rsanÄ±z o engeli aÅŸabilecek, Ã§Ã¶zebilecek bir platform vardÄ±r belki. Yani hÃ¼nerlerinizi sergileyebileceÄŸiniz bir yemek kamyonunu bulabilirsiniz. Ä°ÅŸte bu videonun sponsoru build store. Tam da bu food truck metaforunun e-ticaret dÃ¼nyasÄ±ndaki karÅŸÄ±lÄ±ÄŸÄ± gibi. BÃ¼yÃ¼k bir e-ticaret sitesini kurabilmek iÃ§in Ã§evik bir ÅŸekilde yola Ã§Ä±kmanÄ±zÄ± saÄŸlÄ±yor. Kendi Ã¼rÃ¼nlerinizi satmaya hemen baÅŸlayabileceÄŸiniz bir araÃ§. Yapay zeka destekli algoritmalarla gÃ¼Ã§lendirilmiÅŸ bu aracÄ± kullanarak e-ticaret dÃ¼nyasÄ±na herkes girebilir. Sadece 2 dakika iÃ§inde seÃ§tiÄŸiniz kategoriye Ã¶zel en Ã§ok satan 10 Ã¼rÃ¼nle birlikte hazÄ±r bir online maÄŸazaya sahip olabilirsiniz. Hem de Ã§ok kolay bir ÅŸekilde Ã¶nce Build Your Store'a Ã¼ye oluyor ilginizi Ã§eken bir kategori seÃ§iyorsunuz. Shopify Ã¼zerinden aylÄ±k 1 dolarlÄ±k baÅŸlangÄ±Ã§ planÄ±na geÃ§iyorsunuz. ArdÄ±ndan build your store uygulamasÄ±nÄ± kurup maÄŸazanÄ±zÄ± yapay zeka yardÄ±mÄ±yla bir tÄ±kla oluÅŸturuyorsunuz. Oto DS'i entegre edip Ã¼rÃ¼n ekleme ve sipariÅŸ yÃ¶netimini de otomatikleÅŸtirebiliyorsunuz. Ve iÅŸte maÄŸazanÄ±z hazÄ±r bile. Az Ã¶nceki ÅŸef nasÄ±l kullanman gerektiÄŸini Ã¶ÄŸreteceÄŸim demiÅŸti ya. Build Your Store platformu da size satÄ±ÅŸa hazÄ±r Ã¼rÃ¼n sayfalarÄ± ve Ã¼cretsiz dropshipping eÄŸitimleri sunuyor. Normalde 200-250 dolar deÄŸerindeki premium temada Ã¼cretsiz olarak sizin oluyor. 40.000den fazla giriÅŸimcinin kullanmaya baÅŸladÄ±ÄŸÄ± build your store Ã¼zerinden hemen ÅŸimdi bir Shopify maÄŸazasÄ± aÃ§arsanÄ±z ilk 3 ay sadece aylÄ±k 1 dolar Ã¶deyeceksiniz. Bu fÄ±rsatÄ± kaÃ§Ä±rmamak ve hÄ±zla e-ticaret sitenizi oluÅŸturmak iÃ§in aÃ§Ä±klamalar bÃ¶lÃ¼mÃ¼nde bu kanala Ã¶zel baÄŸlantÄ±yÄ± kullanmayÄ± unutmayÄ±n. Ä°ÅŸte hayattaki en bÃ¼yÃ¼k tutkusu yemek yapmak olan ÅŸefimiz kendisini bÃ¶yle ayaÄŸa kaldÄ±rÄ±yor. >> O yemek kamyonuyla bir yolculuÄŸa Ã§Ä±kÄ±yorlar. Hani hikayecilik de vardÄ±r ya kahramanÄ±n yolculuÄŸu. BÃ¶yle baÅŸlÄ±yor. Kent kent, sokak sokak dolaÅŸÄ±yorlar. Eskiye ait kendi yeteneklerini oÄŸlunun temsil ettiÄŸi yeni nesil becerilerle buluÅŸturuyor. Bir yandan sandviÃ§ yapÄ±p satarken bir yandan sosyal medyayile bunun pazarlamasÄ±nÄ± yapÄ±yorlar. hani o eski iÅŸini yok eden sosyal medyadan korkmak yerine Twitter'Ä± kullanarak kendine bir kitle oluÅŸturuyor. Yani kendisini Ã¶ldÃ¼ren bu bÄ±Ã§aÄŸÄ± bu kez yine kendisini diriltmek iÃ§in kullanÄ±yor. Ä°ÅŸte en Ã¶nemli mesele bu. BÄ±Ã§aÄŸÄ± iyi tanÄ±yacaksÄ±n. Onu adeta bir uzantÄ±nÄ± haline getireceksin. Evet, gerÃ§ekten de Ã¶yle. Bir yandan bu bÄ±Ã§ak Ã§ok keskin. BazÄ±larÄ± iÃ§in tehlikeli. Teknoloji tam olarak bÃ¶yle bir ÅŸey. Ä°nternet Ã§Ä±ktÄ±, geleneksel ekonomiyi keskin bir bÄ±Ã§ak gibi deÄŸiÅŸtirdi. Sosyal medya Ã§Ä±ktÄ±. Dikkatli olmayanlar orada kendini kaybetti. Ve ÅŸimdi yapay zeka var. O da bir bÄ±Ã§ak. Onda da ustalaÅŸmak gerekiyor. Ama nasÄ±l? Yani bu senin iÅŸin. GeliÅŸtirmen gereken senin kendi yeteneÄŸin. AltÄ±n bilezik gibi. Bunu bileÄŸini bir kere taktÄ±n hangi mutfaÄŸa girersen gir artÄ±k hÃ¼nerlerini gÃ¶stermeye baÅŸlayabilirsin. O bÄ±Ã§aÄŸÄ± keskin ve temiz tutup kaybetmemek artÄ±k senin sorumluluÄŸun. Åimdi burada oÄŸluyla bir baÄŸ kurmaya Ã§alÄ±ÅŸan bir baba figÃ¼rÃ¼ var gibi duruyor ama aslÄ±nda her ikisi de birbirine bir ÅŸey Ã¶ÄŸretiyor. Baba oÄŸluna yemek yapma becerisini eskiyi, oÄŸlu da babasÄ±na onu sunma becerisini yeniyi veriyor. Sosyal medyayla nasÄ±l paylaÅŸabileceÄŸini gÃ¶steriyor. Aradaki bÄ±Ã§ak yani teknoloji sadece bu baÄŸÄ±n kurulabilmesini saÄŸlayan bir kÃ¶prÃ¼den ibaret. BugÃ¼n olsa yapay zekayla onu daha iyi hale getirmenin yollarÄ±nÄ± arayÄ±p bulurlardÄ±. Ä°ÅŸin aslÄ± ne biliyor musunuz arkadaÅŸlar? Ä°ÅŸin aslÄ± Ã¶nce yemeÄŸin iÃ§indekilere bakmak, malzemelere. Elde hangi malzeme var? OnlarÄ± bir gÃ¶zden geÃ§ir. Sonra ne piÅŸireceÄŸine karar ver. Tam bir giriÅŸimcilik dersi. Bazen en gÃ¼zel yemekler en sade malzemelerle yapÄ±lÄ±r. Sadece doÄŸru bileÅŸimi bulmak gerekiyor. E hayat da bÃ¶yle. Dedim ya en baÅŸta iyi sandviÃ§ yapmayÄ± bilirsen ÅŸu hayatta her ÅŸeyin Ã¼stesinden gelebilirsin diye. Åimdi bu fotoÄŸrafÄ±ma yeniden bakÄ±nca aslÄ±nda o kadar da kÃ¶tÃ¼ bir yemek gibi gÃ¶rÃ¼nmediÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum. Yani iÃ§indeki kÄ±lÃ§Ä±ktan bile bir ders Ã§Ä±karttÄ±m deÄŸil mi? Evet. Belki siz de fotoÄŸraflarda benim gibi bÃ¶yle boÅŸ boÅŸ bakÄ±yor olabilirsiniz. Belki siz de kendinizi kaybolmuÅŸ hissediyor olabilirsiniz. BÃ¼tÃ¼n bu teknolojik yenilikler, Ã¶zellikle de yapay zeka sanki yerimizi alacakmÄ±ÅŸ gibi geliyor olabilir. Yani yÄ±llarca okudum, emek verdim, didindim ama ÅŸimdi iÅŸe yaramaz hale mi geleceÄŸim? HayÄ±r. O fotoÄŸraftaki Jean Favro nasÄ±l ki palyaÃ§oluktan yÃ¶netmenliÄŸe geÃ§erken yeteneklerini hep biliyse bizim de bu Ã§aÄŸda yapmamÄ±z gereken ÅŸey bu. BÄ±Ã§aÄŸÄ±mÄ±zÄ± bilemek. Ben bu kavramÄ± Stephen Covy'den Ã¶ÄŸrenmiÅŸtim. Ormanda aÄŸaÃ§ keserken durup baltayÄ± bilemek iÃ§in zaman ayÄ±rmak gerekiyor." diye yazmÄ±ÅŸtÄ± Etkili Ä°nsanlarÄ±n YediÄŸi AlÄ±ÅŸkanlÄ±ÄŸÄ± adlÄ± kitabÄ±nda. GÃ¶rÃ¼nÃ¼rde bu bir zaman kaybÄ± gibi gelebilir ama aslÄ±nda uzun vadede en bÃ¼yÃ¼k kazancÄ±n yoludur. BÄ±Ã§aÄŸÄ± bilemek, yeteneklerinizi geliÅŸtirmek, teknolojik yetkinliÄŸinizi arttÄ±rmak. SormamÄ±z gereken soru bÄ±Ã§aÄŸÄ±mÄ±z ne? Belki insanlarla iletiÅŸim kurma yeteneÄŸiniz, belki yaratÄ±cÄ± fikirler Ã¼retme gÃ¼cÃ¼nÃ¼z, belki sabrÄ±nÄ±z, belki Ã¶ÄŸrenme tutkunuz. O bÄ±Ã§aÄŸÄ± nasÄ±l daha keskin hale getirebilirsin? Hangi eÄŸitimle, hangi deneyimle, hangi pratikle onu bileyle? Kim bilir belki senin iyi sandviÃ§in bir podcast fikridir ya da bir dijital Ã¼rÃ¼n, bir e-ticaret sitesidir. Åef filmindeki o food truck metaforunu unutmamak lazÄ±m. Ã‡Ã¼nkÃ¼ o sÄ±fÄ±rdan baÅŸlamak zorunda olan kahramanÄ±mÄ±za kÃ¼Ã§Ã¼k, Ã§evik, hemen harekete geÃ§ebileceÄŸi bir baÅŸlangÄ±Ã§ noktasÄ± gÃ¶revini gÃ¶rdÃ¼. Yani aslÄ±nda mesele ÅŸu. BÄ±Ã§aÄŸÄ± sen tutuyorsun. Elindeki malzemelere bakÄ±yorsun ve ÅŸimdi yapman gereken tek ÅŸey de kendi food truck yolculuÄŸuna Ã§Ä±kmak. Ä°ÅŸin sÄ±rrÄ± burada baÅŸlamakta. HayatÄ±n hangi dÃ¶nemecinde olursan ol yeniden baÅŸlamak mÃ¼mkÃ¼n. Filmdeki o eski kÃ¼lÃ¼stÃ¼r kamyon gibi baÅŸlamak iÃ§in mÃ¼kemmel olmak zorunda da deÄŸilsin. Ama mÃ¼kemmelleÅŸmek iÃ§in baÅŸlaman gerekiyor. Ã–nemli olan yola Ã§Ä±kmak, yolda Ã¶ÄŸrenmek. Yapay zekada, sosyal medyada, hayatÄ±n getirdiÄŸi tÃ¼m zorluklarda sadece birer engel, birer bÄ±Ã§ak, onlarÄ± nasÄ±l tutacaÄŸÄ±nÄ±z, onlarÄ± neye dÃ¶nÃ¼ÅŸtÃ¼receÄŸiniz hep sizin elinizde. O yÃ¼zden ÅŸimdi elinizdeki malzemelere bir bakÄ±n. BÄ±Ã§aÄŸÄ±nÄ±zÄ± tekrar elinize alÄ±n. Onu bir gÃ¼zel bileyin ve yapabileceÄŸiniz en iyi sandviÃ§i yapmaya baÅŸlayÄ±n. [MÃ¼zik]"""

    print("Orijinal Metin UzunluÄŸu:", len(sample_text.split()))
    print("\n" + "=" * 50)

    # 1. NLTK ile Ã¶zetleme
    print("\n1. NLTK ile Ã–zetleme:")
    summary1 = nltk_summarize(sample_text, 2)
    print(summary1)
    print(f"Ã–zet UzunluÄŸu: {len(summary1.split())} kelime")

    # 2. TextRank ile Ã¶zetleme
    print("\n2. TextRank ile Ã–zetleme:")
    summary2 = textrank_summarize(sample_text, 2)
    print(summary2)
    print(f"Ã–zet UzunluÄŸu: {len(summary2.split())} kelime")

    # 3. AI ile Ã¶zetleme (yorum satÄ±rÄ±nÄ± kaldÄ±r ve transformers kur)
    # print("\n3. AI (BART) ile Ã–zetleme:")
    # summary3 = ai_summarize(sample_text)
    # print(summary3)
    # print(f"Ã–zet UzunluÄŸu: {len(summary3.split())} kelime")

    # 4. Basit frekans ile Ã¶zetleme (iyileÅŸtirilmiÅŸ)
    print("\n4. Ä°yileÅŸtirilmiÅŸ Frekans ile Ã–zetleme:")
    summary4 = simple_frequency_summarize(sample_text, 2)
    print(summary4)
    print(f"Ã–zet UzunluÄŸu: {len(summary4.split())} kelime")

    # 5. Transkript Ã¶zetleme testi
    print("\n5. YouTube/Podcast Transkripti Ã–zetleme:")
    # Bu Ã¶rnek iÃ§in gerÃ§ek transkript yerine sample_text kullanÄ±yoruz
    summary5 = transcript_summarize(sample_text, 3)
    print(summary5)
    print(f"Ã–zet UzunluÄŸu: {len(summary5.split())} kelime")

# GEREKLÄ° KÃœTÃœPHANELERÄ° KURMA
"""
Terminal'de ÅŸu komutlarÄ± Ã§alÄ±ÅŸtÄ±r:

pip install nltk
pip install scikit-learn
pip install numpy

# AI Ã¶zetleme iÃ§in (opsiyonel - bÃ¼yÃ¼k model):
pip install transformers torch

# TÃ¼rkÃ§e metin iÃ§in:
pip install turkish-nlp
"""